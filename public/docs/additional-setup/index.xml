<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>更多指南 on FastGPT</title>
    <link>/docs/additional-setup/</link>
    <description>Recent content in 更多指南 on FastGPT</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language><atom:link href="/docs/additional-setup/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>提示词示例</title>
      <link>/docs/additional-setup/prompt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/additional-setup/prompt/</guid>
      <description>客服 link 您好您将扮演万千紧固件公司的售前客服。在第一次咨询中，您需要获取客户的联系人姓名和手机号码，并了解客户是终端生产企业还是工贸经销商。以下是万千紧固件的背景资料：成立于2009年，是一家致力于高质服务的工业零部B2B平台，主要售紧固件，提供标准件和非标定制服务，在河北永年和江苏戴南均有自己的源头工厂，总部位于江苏省无锡市。 您需要遵守以下规则： 1、热情友好，让客户感到愉悦； 2、对于产品专业问题无法回答或客户不满意，留下联系方式让专业产品经理负责； 3、回答问题时言简意赅，仔细思考； 4、客户问产品是否有货时，不要回答没有，而是说我们都能提供； 5、与客户进行简短沟通，了解需求并确认所需产品后，索要联系方式。 样本示例1： 客户：在吗？ 客服：在的，请问您需要咨询什么产品？ 客户：防盗螺栓有吗？ 客服：有的，我们提供全品类的紧固件产品，请告诉我具体的型号和用途。 客户：用在铁塔机器上的，2040304不锈钢 客服：请问需要多少件？ 客户：大概10万颗左右吧 客户：给我个报价，优惠些，长期合作 客服：非常抱歉，报价需要我们专业的产品同事，您能留下联系方式吗？我会安排他们立即与您联系。 客户：王先，13928916752今天能联系么 客服：可以的，我们的同事会在1个小时内与您联系，请注意接听来自无锡的电话。谢谢您的咨询。 样本示例2： 客户：请问一下这个螺栓有没有33长度的？ 客服：您好，我是客服小万，请问您需要的是哪种螺栓？能说得更具体一些吗？ 客户：圆头方颈。 客服：头部多大？ 客户：13。 客户：M6的。 客服：您要的是哪个材质的呢？ 客户：碳钢的，强度高一点。 客服：您需要多少个呢？ 客户：大约2000个左右。 客服：方便留下您的联系方式吗？ 客服：我会让同事在上午与您确认并回复。 客户：18217699040。 客服：请问您的姓氏是？ 客户：王。 客服：好的。 客户：谢谢。 样本示例3： 客户：你们是生产还是贸易？ 客服：亲，感谢您的咨询。我们既生产也贸易，同时接受标准件和非标定制的订单。请问您需要采购什么产品？ 客户：SPR25x100L铜套的304材质螺母M64。 客户：我想找源头工厂。 客服：亲，我们就是源头工厂哦！请问您是关心价格还是质量呢？我们万千是国内大品牌，价格实惠，质量和交期都有保障。 客户：工厂放心点，经销商门道太多。 客服：亲，您可以放心，我们的产品质量有保障，如有不满意可退换；有问题我们也有专属客服经理24小时处理。 客服：请问您具体需要多少数量呢？ 客户：2456个。 客户：什么时候能给出报价？我这边比较着急使用。 客服：亲，请留下您的联系方式，我会让我们专业的产品同事与您联系。 客户：13928956789，李。 样本示例4： 客户：你好，在吗？ 客服：在的。 客服：请问您需要什么产品？ 客户：卡箍有吗？ 客服：有的，您需要哪一种？ 客户：我是用在电线杆上的。 客户：我需要200个。 客服：好的，您需要什么材质的？ 客户：有图片吗？我想看看是不是我需要的那种，材质无所谓。 客服：好的，方便加您微信吗？在线上不方便发图片，加微信后我会给您发送图片以进行确认。 客户：您的微信是多少？我加您。 客服：好的，我的微信是18626076792，您可以添加一下。您也可以直接拨打电话与我们联系。 客户：已添加，请通过微信沟通。 客服：好的，已通过，我需要记录一下，请问您的电话方便吗？ 客户：187628100000。 服：请问您的姓氏是？ 客户：陈。 客服：好的。 客户：谢谢。 样本示例5： 客户：87322.</description>
    </item>
    
    <item>
      <title>对接第三方 GPT 应用</title>
      <link>/docs/additional-setup/openai/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/additional-setup/openai/</guid>
      <description>获取 API 秘钥 link依次选择应用 -&amp;gt; 「API访问」，然后点击「API 密钥」来创建密钥。
warning 密钥需要自己保管好，一旦关闭就无法再复制密钥，只能创建新密钥再复制。
组合秘钥 link利用刚复制的 API 秘钥加上 AppId 组合成一个新的秘钥，格式为：API 秘钥-AppId，例如：fastgpt-z51pkjqm9nrk03a1rx2funoy-642adec15f04d67d4613efdb。
替换三方应用的变量 link OPENAI_API_BASE_URL: https://fastgpt.run/api/openapi (改成自己部署的域名) OPENAI_API_KEY = 组合秘钥 ChatGPT Next Web 示例：
ChatGPT Web 示例：</description>
    </item>
    
    <item>
      <title> 接入 ChatGLM2-6B</title>
      <link>/docs/additional-setup/chatglm2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/additional-setup/chatglm2/</guid>
      <description>前言 linkFastGPT 允许你使用自己的 OpenAI API KEY 来快速调用 OpenAI 接口，目前集成了 GPT-3.5, GPT-4 和 embedding，可构建自己的知识库。但考虑到数据安全的问题，我们并不能将所有的数据都交付给云端大模型。
那么如何在 FastGPT 上接入私有化模型呢？本文就以清华的 ChatGLM2 为例，为各位讲解如何在 FastGPT 中接入私有化模型。
ChatGLM2-6B 简介 linkChatGLM2-6B 是开源中英双语对话模型 ChatGLM-6B 的第二代版本，具体介绍可参阅 ChatGLM2-6B 项目主页。
warning 注意，ChatGLM2-6B 权重对学术研究完全开放，在获得官方的书面许可后，亦允许商业使用。本教程只是介绍了一种用法，无权给予任何授权！
推荐配置 link依据官方数据，同样是生成 8192 长度，量化等级为 FP16 要占用 12.8GB 显存、int8 为 8.1GB 显存、int4 为 5.1GB 显存，量化后会稍微影响性能，但不多。
因此推荐配置如下：
类型 内存 显存 硬盘空间 启动命令 fp16 &amp;gt;=16GB &amp;gt;=16GB &amp;gt;=25GB python openai_api.py 16 int8 &amp;gt;=16GB &amp;gt;=9GB &amp;gt;=25GB python openai_api.py 8 int4 &amp;gt;=16GB &amp;gt;=6GB &amp;gt;=25GB python openai_api.</description>
    </item>
    
    <item>
      <title> 打造高质量 AI 知识库</title>
      <link>/docs/additional-setup/kb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/additional-setup/kb/</guid>
      <description>前言 link自从去年 12 月 ChatGPT 发布后，带动了新的一轮应用交互革命。尤其是 GPT-3.5 接口全面放开后，LLM 应用雨后春笋般快速涌现，但因为 GPT 的可控性、随机性和合规性等问题，很多应用场景都没法落地。
3 月时候，在 Twitter 上刷到一个老哥使用 GPT 训练自己的博客记录，并且成本非常低（比起 FT）。他给出了一个完整的流程图：
看到这个推文后，我灵机一动，应用场景就十分清晰了。直接上手开干，在经过不到 1 个月时间，FastGPT 在原来多助手管理基础上，加入了向量搜索。于是便有了最早的一期视频：
&lt;!DOCTYPE HTML&gt; 3 个月过去了，FastGPT 延续着早期的思路去完善和扩展，目前在向量搜索 + LLM 线性问答方面的功能基本上完成了。不过我们始终没有出一期关于如何构建知识库的教程，趁着 V4 在开发中，我们计划介绍一期《如何在 FastGPT 上构建高质量知识库》，以便大家更好的使用。
FastGPT 知识库完整逻辑 link在正式构建知识库前，我们先来了解下 FastGPT 是如何进行知识库检索的。首先了解几个基本概念：
向量：将人类直观的语言（文字、图片、视频等）转成计算机可识别的语言（数组）。 向量相似度：两个向量之间可以进行计算，得到一个相似度，即代表：两个语言相似的程度。 语言大模型的一些特点：上下文理解、总结和推理。 结合上述 3 个概念，便有了 “向量搜索 + 大模型 = 知识库问答” 的公式。下图是 FastGPT V3 中知识库问答功能的完整逻辑：
与大部分其他知识库问答产品不一样的是， FastGPT 采用了 QA 问答对进行存储，而不是仅进行 chunk（文本分块）处理。目的是为了减少向量化内容的长度，让向量能更好的表达文本的含义，从而提高搜索精准度。 此外 FastGPT 还提供了搜索测试和对话测试两种途径对数据进行调整，从而方便用户调整自己的数据。根据上述流程和方式，我们以构建一个 FastGPT 常见问题机器人为例，展示如何构建一个高质量的 AI 知识库。
构建知识库应用 link首先，先创建一个 FastGPT 常见问题知识库</description>
    </item>
    
  </channel>
</rss>
