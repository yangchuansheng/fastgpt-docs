<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>配置说明 on FastGPT</title>
    <link>/docs/reference/</link>
    <description>Recent content in 配置说明 on FastGPT</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language><atom:link href="/docs/reference/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>配置详解</title>
      <link>/docs/reference/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/configuration/</guid>
      <description>由于环境变量不利于配置复杂的内容，新版 FastGPT 采用了 ConfigMap 的形式挂载配置文件，你可以在 client/data/config.json 看到默认的配置文件。可以参考 docker-compose 快速部署 来挂载配置文件。
开发环境下，你需要将示例配置文件 config.json 复制成 config.local.json 文件才会生效。
注意: 为了方便介绍，文档介绍里会把注释写到 json 文件，实际运行时候 json 文件不能包含注释。
这个配置文件中包含了前端页面定制、系统级参数、AI 对话的模型等……
warning 注意：下面的配置介绍仅是局部介绍，你需要完整挂载整个 config.json，不能仅挂载一部分。你可以直接在默认的 config.json 基础上根据下面的介绍进行修改。
基础字段粗略说明 link这里介绍一些基础的配置字段：
// 这个配置会控制前端的一些样式 &amp;#34;FeConfig&amp;#34;: { &amp;#34;show_emptyChat&amp;#34;: true, // 对话页面，空内容时，是否展示介绍页 &amp;#34;show_register&amp;#34;: false, // 是否展示注册按键（包括忘记密码，注册账号和三方登录） &amp;#34;show_appStore&amp;#34;: false, // 是否展示应用市场（不过目前权限还没做好，放开也没用） &amp;#34;show_userDetail&amp;#34;: false, // 是否展示用户详情（账号余额、OpenAI 绑定） &amp;#34;show_git&amp;#34;: true, // 是否展示 Git &amp;#34;systemTitle&amp;#34;: &amp;#34;FastGPT&amp;#34;, // 系统的 title &amp;#34;authorText&amp;#34;: &amp;#34;Made by FastGPT Team.&amp;#34;, // 签名 &amp;#34;gitLoginKey&amp;#34;: &amp;#34;&amp;#34; // Git 登录凭证 }, .</description>
    </item>
    
    <item>
      <title>多模型支持</title>
      <link>/docs/reference/models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/models/</guid>
      <description>默认情况下，FastGPT 只配置了 GPT 的 3 个模型，如果你需要接入其他模型，需要进行一些额外配置。
部署 one-api link首先你需要部署一个 one-api，并添加对应的【渠道】
添加 FastGPT 配置 link可以在 /client/src/data/config.json 里找到配置文件（本地开发需要复制成 config.local.json），配置文件中有一项是对话模型配置：
&amp;#34;ChatModels&amp;#34;: [ { &amp;#34;model&amp;#34;: &amp;#34;gpt-3.5-turbo&amp;#34;, // 这里的模型需要对应 OneAPI 的模型 &amp;#34;name&amp;#34;: &amp;#34;FastAI-4k&amp;#34;, // 对外展示的名称 &amp;#34;contextMaxToken&amp;#34;: 4000, // 最大长下文 token，无论什么模型都按 GPT35 的计算。GPT 外的模型需要自行大致计算下这个值。可以调用官方接口去比对 Token 的倍率，然后在这里粗略计算。 // 例如：文心一言的中英文 token 基本是 1:1，而 GPT 的中文 Token 是 2:1，如果文心一言官方最大 Token 是 4000，那么这里就可以填 8000，保险点就填 7000. &amp;#34;quoteMaxToken&amp;#34;: 2000, // 引用知识库的最大 Token &amp;#34;maxTemperature&amp;#34;: 1.2, // 最大温度 &amp;#34;price&amp;#34;: 1.5, // 1个token 价格 =&amp;gt; 1.</description>
    </item>
    
  </channel>
</rss>
